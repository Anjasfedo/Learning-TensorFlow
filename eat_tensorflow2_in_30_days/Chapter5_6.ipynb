{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvqlbJJSzHWW6QTKLjTO4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjasfedo/Learning-TensorFlow/blob/main/eat_tensorflow2_in_30_days/Chapter5_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-6 metrics"
      ],
      "metadata": {
        "id": "IdwhOr0QlSlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides being used as optimization target during training, loss function also acts as an evaluation remark of model performance. However in general, the performance of the model is evaluated using other terms.\n",
        "\n",
        "This is evaluation metrics. Loss function could be used as metrics. `MAE`, `MSE`, `CategoricalCrossentropy` are several most common metrics.\n",
        "\n",
        "However, metrics is not necessarily able to act as loss function, such as `AUC`, `Accuracy`, `Precision`. This is because metrics is not required to be continously differentiable, while this is a general requirement for the loss funcion.\n",
        "\n",
        "Metrics could be customized if necessary.\n",
        "\n",
        "The customized metrics requires two tensor `y_true` and `y_pred` as input, and output a scalar as the value of the calculated metrics.\n",
        "\n",
        "It is also possible to customized metrics through inheriting from the base class `tf.keras.metrics.Metric` and rewrite the `init`, `update_state`, `result` methods to implement the calculation of metrics.\n",
        "\n",
        "Usually the training are performed batch by batch, while metrics could be calculated only after a whole epoch, thus the class-type metrics is more popular. We need to write initialization method to create the necessary middle variables (they are related to the resulting metrics), write the `update_state` method to update the states of these middle variables after each batch, and write the `result` method for the final output.\n",
        "\n",
        "If the metrics is writter as a function, it is only possible to use de avaranged metrics among all the batches in the epoch as the overall metrics. This usually deviated from the result calculated by all training steps in the epoch."
      ],
      "metadata": {
        "id": "Nz_hSpAHlUuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Most Frequently Used Pre-defined Metrics\n",
        "\n",
        "- MeanSquaredError (Mean Squared Error, used for regression, dubbed as \"MSE\", function name `mse`)\n",
        "- MeanAbsoluteError (Mean Absolute Error, used for regression, dubbed as \"MAE\", function name `mae`)\n",
        "- MeanAbsolutePercentageError (Mean Absolute Percentage Error, used for regression, dubbed as \"MAPE\", function name `mape`)\n",
        "- RootMeanSquaredError (Root-Mean-Squared-Error, used for regression)\n",
        "- Accuracy (Accuracy, used for classfication, could be representated as a string \"Accuracy\"; Accuracy = (TP + TN) / (TP + TN + FP + FN); requires ordinal encoding for the inputs `y_true` and `y_pred`)\n",
        "- Precision (Precision, used for binary classfication; Precision = TP / (TP + FP))\n",
        "- Recall (Recalling rate, used for binary classification; Recall = Tp / (TP + FN))\n",
        "- TruePositives (True Positives, used for binary classification)\n",
        "- TrueNegatives (True Negatives, used for binary classification)\n",
        "- FalsePositives (False Positives, used for binary classification)\n",
        "- FalseNegatives (False Negatives, used for binary classification)\n",
        "= AUC (Area Under the Curve, represents the area under the ROC curve (TPR vs FPR); it is used for binary classification. An intuitive explanation: pick a positive sample and a negative sample, AUC is possibility that the prediction of positive sample larger than the prediction of the negative sample)\n",
        "- CategoricalAccuracy (Categorical Accuracyl, same as `Accuracy` except requiring one-hot encoding for the input label `y_true`)\n",
        "- SparseCategoricalAccuracy (Spatial Categorical Accuracy, same as `Accuracy` except requiring ordinal encoding for the label `y_true`)\n",
        "- MeanIloU (Intersection-Over-Union, usually for image segmentation)\n",
        "- TopKCategoricalAccuracy (TopK Accuracy for multiple classification, requires ordinary encoding for the input label `y_true`)\n",
        "- Mean (Mean Value)\n",
        "- Sum (Summation)"
      ],
      "metadata": {
        "id": "A8dqJkGtnM_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Customized Metrics\n",
        "\n",
        "Here the K-S (Kolmogorov-Smirnov) statistic, which is frequently used in financial risk management, as an example for the customized metrics.\n",
        "\n",
        "K-S statistic is used for binary classification problem; KS = max(TPR - FPR), where TPR = TP / (TP + FN), FPR = FP / (FP + TN).\n",
        "\n",
        "TPR curve is the cumulative distribution function (CDF) of the positive samples while FPR curve is the CDF of the negative samples.\n",
        "\n",
        "K-S statistic is the maximum of the difference between the CDF of positive and negative samples."
      ],
      "metadata": {
        "id": "Vw9S8rSEqt8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kwa-fC1vlLza"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customized metrics defined by function\n",
        "@tf.function\n",
        "def ks (y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, (-1,))\n",
        "  y_pred = tf.reshape(y_pred, (-1,))\n",
        "  length = tf.shape(y_true)[0]\n",
        "  t = tf.math.top_k(y_pred, k=length, sorted=False)\n",
        "  y_pred_sorted = tf.gather(y_pred, t.indices)\n",
        "  y_true_sorted = tf.gather(y_true, t.indices)\n",
        "\n",
        "  cum_positive_ratio = tf.truediv(\n",
        "      tf.cumsum(y_true_sorted), tf.reduce_sum(y_true_sorted))\n",
        "  cum_negative_ratio = tf.truediv(\n",
        "      tf.cumsum(1 - y_true_sorted), tf.reduce_sum(1 - y_true_sorted))\n",
        "  ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio))\n",
        "\n",
        "  return ks_value"
      ],
      "metadata": {
        "id": "FsjP2q3Frmoe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.constant([[1], [1], [1], [0], [1], [1], [1], [0], [0], [0], [1], [0], [1], [0]])\n",
        "y_pred = tf.constant([[0.6], [0.1], [0.4], [0.5], [0.7], [0.7], [0.7],\n",
        "                      [0.4], [0.4], [0.5], [0.8], [0.3], [0.5], [0.3]])\n",
        "\n",
        "print(ks(y_true,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOz0ZMMjrmkl",
        "outputId": "2b7af494-5e18-42ae-f415-58b24d6e9640"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.625, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customized metrics defined by class\n",
        "class KS(metrics.Metric):\n",
        "  def __init__(self, name='ks', **kwargs):\n",
        "    super(KS, self).__init__(name=name, **kwargs)\n",
        "    self.true_positive = self.add_weight(name='tp', initializer='zeros', shape=(101,))\n",
        "    self.false_positive = self.add_weight(name='fp', initializer='zeros', shape=(101,))\n",
        "\n",
        "  @tf.function\n",
        "  def update_state(self, y_true, y_pred):\n",
        "    y_true = tf.cast(tf.reshape(y_true, (-1,)), tf.bool)\n",
        "    y_pred = tf.cast(100 * tf.reshape(y_pred, (-1,)), tf.int32)\n",
        "\n",
        "    for i in tf.range(0, tf.shape(y_true)[0]):\n",
        "      if y_true[i]:\n",
        "        self.true_positive[y_pred[i]].assign(\n",
        "            self.true_positive[y_pred[i]] + 1.0)\n",
        "      else:\n",
        "        self.false_positive[y_pred[i]].assign(\n",
        "            self.false_positive[y_pred[i]] + 1.0)\n",
        "\n",
        "    return (self.true_positive, self.false_positive)\n",
        "\n",
        "  @tf.function\n",
        "  def result(self):\n",
        "    cum_positive_ratio = tf.truediv(\n",
        "        tf.cumsum(self.true_positive), tf.reduce_sum(self.true_positive))\n",
        "    cum_negative_ratio = tf.truediv(\n",
        "        tf.cumsum(self.false_positive), tf.reduce_sum(self.false_positive))\n",
        "    ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio))\n",
        "\n",
        "    return ks_value"
      ],
      "metadata": {
        "id": "TwFEt_pArmfx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myks = KS()\n",
        "myks.update_state(y_true,y_pred)\n",
        "print(myks.result())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5e-GFLvrma9",
        "outputId": "8da3b7bc-e322-48f7-8a9f-dfc136c7cb7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.625, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceX_a-4lrmVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vo_P9TjUrmRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2_jg1zprl0w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}