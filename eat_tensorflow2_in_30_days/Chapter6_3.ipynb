{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXbBJqfKDq3jvFu6VXS6eC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjasfedo/Learning-TensorFlow/blob/main/eat_tensorflow2_in_30_days/Chapter6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-3 Model Training Using Single GPU"
      ],
      "metadata": {
        "id": "4gGCGBs-JDoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training procedure of deep learning is usually time consuming. It even takes tens of days for training, and there is no need to mention those take days or hours.\n",
        "\n",
        "The time is mainly consumpted by two stages, data preparation and parameter iteration.\n",
        "\n",
        "We can increase the number of process to alleviate this issue if data preparation takes the majority of time.\n",
        "\n",
        "However if the majority of time is taken by parameter iteration, we need to use GPU or Google TPU for acceleration.\n",
        "\n",
        "There is no need to modify source code for switching from CPU to GPU when using the pre-defined `fit` method or the customized training loops. When GPU is available and the device is not specified, TensorFlow automatically chooses GPU for tensor creating and computing.\n",
        "\n",
        "However, for the case of using shared GPU with multiple users, such as using server of the company or the lab, we need to add following code to specify the GPU ID and the GPU memory size that we are going to use, in order to avoid the GPU resources to be occupied by a single user (actually TensorFlow aqcuires all GPU cors and all GPU memories by default) and allows multiple users perform training on it.\n",
        "\n",
        "In Colab notebook, choose GPU in Edit -> Notebook Settings -> Hardware Accelerator\n",
        "\n",
        "Note: the following code only executes on Colab"
      ],
      "metadata": {
        "id": "8Us0ekoHN6yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js-1EFJpPeeA",
        "outputId": "8310f1ef-c2fe-484b-d3b3-e63b48259216"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import *\n",
        "\n",
        "# Time stamp\n",
        "@tf.function\n",
        "def printbar():\n",
        "  ts = tf.timestamp()\n",
        "  today_ts = ts%(24*60*60)\n",
        "\n",
        "  hour = tf.cast(today_ts%3600, tf.int32)%tf.constant(24)\n",
        "  minute = tf.cast((today_ts%3600)//60, tf.int32)\n",
        "  second = tf.cast(tf.floor(today_ts%60), tf.int32)\n",
        "\n",
        "  def timeformat(m):\n",
        "    if tf.strings.length(tf.strings.format(\"{}\", m))==1:\n",
        "      return(tf.strings.format(\"0{}\", m))\n",
        "    else:\n",
        "      return(tf.strings.format(\"{}\", m))\n",
        "\n",
        "  timestrings = tf.strings.join([timeformat(hour), timeformat(minute), timeformat(second)], separator = \":\")\n",
        "  tf.print(\"==========\"*8 + \"\\n\" + timestrings, \"\\n\" + \"==========\"*8 + \"\\n\")"
      ],
      "metadata": {
        "id": "9BbLuyuVPeaT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. GPU Configuration"
      ],
      "metadata": {
        "id": "Ub1z7xpBRljH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "\n",
        "if gpus:\n",
        "    gpu0 = gpus[0] # Only use GPU 0 when existing multiple GPUs\n",
        "    tf.config.experimental.set_memory_growth(gpu0, True) # Set the usage of GPU memory according to needs\n",
        "    # The GPU memory usage could also be fixed (e.g. 4GB)\n",
        "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
        "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
        "    tf.config.set_visible_devices([gpu0],\"GPU\")"
      ],
      "metadata": {
        "id": "XJPKgWfDPeWQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the computing speed between GPU and CPU."
      ],
      "metadata": {
        "id": "tiDWdshpSyh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "printbar()\n",
        "with tf.device('/gpu:0'):\n",
        "  tf.random.set_seed(0)\n",
        "  a = tf.random.uniform((100000, 100), minval=0, maxval=3.0)\n",
        "  b = tf.random.uniform((100, 1000), minval=0, maxval=3.0)\n",
        "  c = a@b\n",
        "\n",
        "  tf.print(tf.reduce_sum(tf.reduce_sum(c, axis=1), axis=0))\n",
        "printbar()"
      ],
      "metadata": {
        "id": "7F3mFfMPPeOA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printbar()\n",
        "with tf.device(\"/cpu:0\"):\n",
        "    tf.random.set_seed(0)\n",
        "    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n",
        "    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n",
        "    c = a@b\n",
        "    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\n",
        "printbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZfOBHSwPeJr",
        "outputId": "ad612bd2-9c4a-4459-eb64-33fc352b409e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"================================================================================\\n07:38:31\" \n",
            "================================================================================\n",
            "\n",
            "2.24953778e+11\n",
            "\"================================================================================\\n15:38:39\" \n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preparation"
      ],
      "metadata": {
        "id": "Er-UKOWpUQMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 300\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.reuters.load_data()\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=MAX_LEN)\n",
        "\n",
        "MAX_WORDS = x_train.max()+1\n",
        "CAT_NUM = y_train.max()+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snwAsvzsPeFW",
        "outputId": "0d0a4e8a-83a1-4d13-be6b-9ed32fc2601c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \\\n",
        "          .shuffle(buffer_size=1000).batch(BATCH_SIZE) \\\n",
        "          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
        "\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \\\n",
        "          .shuffle(buffer_size=1000).batch(BATCH_SIZE) \\\n",
        "          .prefetch(tf.data.experimental.AUTOTUNE).cache()"
      ],
      "metadata": {
        "id": "9N8KzswaUZeB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Defining"
      ],
      "metadata": {
        "id": "fY6uK8olUkiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def create_model():\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(layers.Embedding(MAX_WORDS, 7, input_length=MAX_LEN))\n",
        "  model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "  model.add(layers.MaxPool1D(2))\n",
        "  model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "  model.add(layers.MaxPool1D(2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(CAT_NUM, activation='softmax'))\n",
        "  return(model)\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "gUFgkKMePeA6",
        "outputId": "98f9e7bc-f682-4c9f-9bdb-edb1097b5613"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model Training"
      ],
      "metadata": {
        "id": "3a3Nkh40U5Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Nadam()\n",
        "loss_func = losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "train_loss = metrics.Mean(name='train_loss')\n",
        "train_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "valid_loss = metrics.Mean(name='valid_loss')\n",
        "valid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
      ],
      "metadata": {
        "id": "d4P59Tp6Pd8d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, features, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(features, training=True)\n",
        "    loss = loss_func(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss.update_state(loss)\n",
        "  train_metric.update_state(labels, predictions)"
      ],
      "metadata": {
        "id": "PcN2UhAiPd4G"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def valid_step(model, features, labels):\n",
        "  predictions = model(features)\n",
        "  batch_loss = loss_func(labels, predictions)\n",
        "  valid_loss.update_state(batch_loss)\n",
        "  valid_metric.update_state(labels, predictions)"
      ],
      "metadata": {
        "id": "EXOvQ_UsVEic"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, ds_train, ds_valid, epochs):\n",
        "  for epoch in tf.range(1, epochs+1):\n",
        "    for features, labels in ds_train:\n",
        "      train_step(model, features, labels)\n",
        "\n",
        "    for features, labels in ds_valid:\n",
        "      valid_step(model, features, labels)\n",
        "\n",
        "    logs = 'Epoch={}, Loss:{}, Accuracy:{}, Valid Loss:{}, Valid Accuracy:{}'\n",
        "\n",
        "    if epoch%1 == 0:\n",
        "      printbar()\n",
        "      tf.print(tf.strings.format(logs,\n",
        "        (epoch, train_loss.result(), train_metric.result(), valid_loss.result(), valid_metric.result())))\n",
        "      tf.print(\"\")\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    valid_loss.reset_states()\n",
        "    train_metric.reset_states()\n",
        "    valid_metric.reset_states()"
      ],
      "metadata": {
        "id": "vh7l7_zIVEeu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, ds_train, ds_test, epochs=6)"
      ],
      "metadata": {
        "id": "kjyLLfV6VEWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uxwuvH1RVETI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xB5OHnIcVEPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZoogtZdEPd0N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2m_Zncy_-XIk"
      },
      "outputs": [],
      "source": []
    }
  ]
}